{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPDYJgS42qUvCnfRKwM5Uh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arielcintra/smart_bot_boy/blob/main/smart_boy_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Flask sentence-transformers pymongo Werkzeug python-docx openpyxl PyPDF2 requests beautifulsoup4 lxml Pillow torch pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiaMuGebLHXl",
        "outputId": "9f3ecb11-e3f6-4a0d-bc24-1e54bde3361f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11)\n",
            "Requirement already satisfied: Werkzeug in /usr/local/lib/python3.11/dist-packages (3.1.3)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug) (3.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Xg9f18aVKtHc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from flask import Flask, request, render_template, jsonify\n",
        "from sentence_transformers import SentenceTransformer, util, InputExample, losses\n",
        "from torch.utils.data import DataLoader\n",
        "from pymongo import MongoClient\n",
        "from werkzeug.utils import secure_filename\n",
        "import docx\n",
        "import openpyxl\n",
        "import csv\n",
        "import PyPDF2\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "from abc import ABC, abstractmethod\n",
        "from pytesseract import image_to_string\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseTextExtractor(ABC):\n",
        "    @abstractmethod\n",
        "    def extract_text(self, file):\n",
        "        pass"
      ],
      "metadata": {
        "id": "OwL41_pBx4zP"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TxtTextExtractor(BaseTextExtractor):\n",
        "    def extract_text(self, file):\n",
        "        return file.read().decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "HxRxV7qyv9XV"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocxTextExtractor(BaseTextExtractor):\n",
        "    def extract_text(self, file):\n",
        "        doc = docx.Document(file)\n",
        "        return \"\\n\".join(para.text for para in doc.paragraphs)"
      ],
      "metadata": {
        "id": "plSXgkT8whQz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class XlsxTextExtractor(BaseTextExtractor):\n",
        "    def extract_text(self, file):\n",
        "        workbook = openpyxl.load_workbook(file)\n",
        "        sheet = workbook.active\n",
        "        return \"\\n\".join(\" \".join(str(cell) for cell in row) for row in sheet.iter_rows(values_only=True))"
      ],
      "metadata": {
        "id": "B1gFc9FawD2Z"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CsvTextExtractor(BaseTextExtractor):\n",
        "    def extract_text(self, file):\n",
        "        reader = csv.reader(file.read().decode('utf-8').splitlines())\n",
        "        return \"\\n\".join(\" \".join(row) for row in reader)"
      ],
      "metadata": {
        "id": "SLjOxxDmwIqP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PdfTextExtractor(BaseTextExtractor):\n",
        "    def extract_text(self, file):\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        return \"\\n\".join(page.extract_text() for page in reader.pages)"
      ],
      "metadata": {
        "id": "-tLGDUL-wLQZ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageTextExtractor(BaseTextExtractor):\n",
        "    def extract_text(self, file):\n",
        "        try:\n",
        "            from pytesseract import image_to_string\n",
        "            image = Image.open(file)\n",
        "            return image_to_string(image)\n",
        "        except ImportError:\n",
        "            return \"OCR library (pytesseract) not installed. Cannot extract text from images.\""
      ],
      "metadata": {
        "id": "SSMd8P-0wNIt"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextExtractorFactory:\n",
        "    @staticmethod\n",
        "    def get_extractor(extension):\n",
        "        extractors = {\n",
        "            'txt': TxtTextExtractor(),\n",
        "            'docx': DocxTextExtractor(),\n",
        "            'xlsx': XlsxTextExtractor(),\n",
        "            'csv': CsvTextExtractor(),\n",
        "            'pdf': PdfTextExtractor(),\n",
        "            'jpg': ImageTextExtractor(),\n",
        "            'jpeg': ImageTextExtractor(),\n",
        "            'png': ImageTextExtractor(),\n",
        "        }\n",
        "        return extractors.get(extension)"
      ],
      "metadata": {
        "id": "rjxrLIU3yPor"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentRepository:\n",
        "    def __init__(self):\n",
        "        self.client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "        self.db = self.client['chatbot_db']\n",
        "        self.collection = self.db['documents']\n",
        "\n",
        "    def insert_document(self, text, embedding):\n",
        "        self.collection.insert_one({\n",
        "            \"text\": text,\n",
        "            \"embedding\": embedding.tolist()\n",
        "        })\n",
        "\n",
        "    def find_all_documents(self):\n",
        "        return self.collection.find()\n",
        "\n",
        "    def get_all_texts(self):\n",
        "        return [doc['text'] for doc in self.collection.find()]"
      ],
      "metadata": {
        "id": "kFcQPGqryXLw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NLPModel:\n",
        "    def __init__(self, model_name=\"paraphrase-MiniLM-L6-v2\"):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "    def encode(self, text):\n",
        "        return self.model.encode(text, convert_to_tensor=True)\n",
        "\n",
        "    def fine_tune(self, train_data: list):\n",
        "        examples = [InputExample(texts=[text], label=1.0) for text in train_data]\n",
        "        train_dataloader = DataLoader(examples, shuffle=True, batch_size=16)\n",
        "        train_loss = losses.CosineSimilarityLoss(self.model)\n",
        "\n",
        "        self.model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1)"
      ],
      "metadata": {
        "id": "6HuB_gQf1WYs"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repository = DocumentRepository()\n",
        "nlp_model = NLPModel()\n",
        "\n",
        "class DocumentService:\n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "        embedding = nlp_model.encode(text)\n",
        "        repository.insert_document(text, embedding)\n",
        "        DocumentService.fine_tune_model()\n",
        "        return \"Text processed and stored successfully!\"\n",
        "\n",
        "    @staticmethod\n",
        "    def process_link(url):\n",
        "        text = DocumentService.extract_text_from_link(url)\n",
        "        if text and len(text) > 0:\n",
        "            embedding = nlp_model.encode(text)\n",
        "            repository.insert_document(text, embedding)\n",
        "            DocumentService.fine_tune_model()\n",
        "            return \"Link content processed and stored successfully!\"\n",
        "        return \"No content retrieved from the URL.\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_text_from_link(url):\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 200:\n",
        "                soup = BeautifulSoup(response.content, 'html.parser')\n",
        "                paragraphs = soup.find_all('p')\n",
        "                text = \"\\n\".join([para.get_text() for para in paragraphs])\n",
        "                return text\n",
        "            else:\n",
        "                return \"Failed to retrieve the webpage.\"\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {e}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def search_answer(question):\n",
        "        question_embedding = nlp_model.encode(question)\n",
        "        documents = repository.find_all_documents()\n",
        "        similarities = []\n",
        "\n",
        "        for doc in documents:\n",
        "            doc_embedding = doc['embedding']\n",
        "            similarity = util.pytorch_cos_sim(question_embedding, torch.tensor(doc_embedding))[0][0]\n",
        "            similarities.append((doc['text'], similarity))\n",
        "\n",
        "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "        return similarities[0][0] if similarities else \"No relevant information found.\"\n",
        "\n",
        "    @staticmethod\n",
        "    def fine_tune_model():\n",
        "        texts = repository.get_all_texts()\n",
        "        if texts:\n",
        "            nlp_model.fine_tune(texts)\n",
        "            return \"Model fine-tuned successfully!\"\n",
        "        return \"No data available for fine-tuning.\""
      ],
      "metadata": {
        "id": "7xQg80sYys1O"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/process_text', methods=['POST'])\n",
        "def process_text():\n",
        "    text = request.json.get(\"text\", \"\")\n",
        "    if text:\n",
        "        response = DocumentService.process_text(text)  # Fine-tuning automático aqui\n",
        "        return jsonify({\"message\": response}), 200\n",
        "    return jsonify({\"message\": \"No text provided.\"}), 400\n",
        "\n",
        "@app.route(\"/process_link\", methods=[\"POST\"])\n",
        "def process_link():\n",
        "    url = request.json.get(\"url\", \"\")\n",
        "    if url:\n",
        "        response = DocumentService.process_link(url)  # Fine-tuning automático aqui\n",
        "        return jsonify({\"message\": response}), 200\n",
        "    return jsonify({\"message\": \"No URL provided.\"}), 400\n",
        "\n",
        "@app.route(\"/search_answer\", methods=[\"POST\"])\n",
        "def search_answer():\n",
        "    question = request.json.get(\"question\", \"\")\n",
        "    if question:\n",
        "        answer = DocumentService.search_answer(question)\n",
        "        return jsonify({\"answer\": answer}), 200\n",
        "    return jsonify({\"answer\": \"No question provided.\"}), 400"
      ],
      "metadata": {
        "id": "04bF1s7vOmIl"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True, port=3978)"
      ],
      "metadata": {
        "id": "nbgH4jNsOt_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93cb1f9f-2eb7-4022-dd84-ac990773d558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:3978\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}